{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kernelblog2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNToih5yOgYZqGYPN0qWIB6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blakebordelon/kernel_blogs/blob/master/kernelblog2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2vjOKCBMkr2",
        "colab_type": "text"
      },
      "source": [
        "# Solving the Kernel Regression Problem Efficiently\n",
        "\n",
        "\n",
        "This is the second blog post in a $k$-part series. \n",
        "\n",
        "In my last [post](https://colab.research.google.com/drive/1XNVNLcUzlpWT0jwS5__p0qXhF7P9tGqd#scrollTo=H5Z4NUdSxgVy), I introduced kernel regression, its mathematical definition, and a [physics-inspired theory of generalization](https://arxiv.org/abs/2002.02561) that agrees well with kernel regression experiments. In this post, we will focus on the *optimization* or training component of the algorithm as opposed to generalization. For those of you most fascinated with the statistical (generalization) puzzles of ML, the next post will be coauthored with Abdulkadir Canatar on [sample-wise multiple descents](https://arxiv.org/abs/2006.13198) when the learning problem is noisy and how we can understand the test error with a phase diagram. \n",
        "\n",
        "Today, however, our focus is very practical. We want to solve the kernel regression optimization problem numerically. The main issues we will discuss\n",
        "\n",
        "1.   Why kernel methods have historically been limited to small datasets.\n",
        "2.   How recent algorithmic advances allow efficient training of *much* larger datasets, even those with [billions of data points](https://arxiv.org/abs/2006.10350).\n",
        "\n",
        "We will discover that solving this problem efficiently is equivalent to solving a large linear system of equations efficiently. We will mostly use Ma and Belkin's [Eigenpro](https://arxiv.org/abs/1703.10622) paper as a guide on this journey. It is quite a good introduction to these issues and goes in much greater depth than I will here.\n",
        "\n",
        "\n",
        "## Problem Definition and Linear Algebra Formulation\n",
        "\n",
        "The setting of the learning problem requires we introduce the following objects\n",
        "\n",
        "1. Supervised learning dataset $\\mathcal D = \\{ (\\mathbf x_1,y_1),...,(\\mathbf x_p,y_p) \\}$ with $p$ data points. \n",
        "\n",
        "2. A reproducing kernel Hilbert space (RKHS) $\\mathcal H$ with reproducing kernel $K$. The Hilbert space has an inner product (for functions) denoted as $\\left< \\cdot , \\cdot \\right>_{\\mathcal H}$. The *reproducing property* is $\\left< g , K(\\cdot, \\mathbf x)  \\right>_{\\mathcal H} = g(\\mathbf x)$\n",
        "3. The objective function that we want to optimize\n",
        "\n",
        "$$ \\min_{f \\in \\mathcal H} \\sum_{i=1}^p \\ell(f(\\mathbf x_i), y_i) + \\lambda \\left< f,f\\right>_{\\mathcal H}$$\n",
        "\n",
        "where $\\ell(\\cdot,\\cdot)$ is a convex loss function (least squares, cross entropy, etc). \n",
        "\n",
        "If any of these things look unfamiliar or stress inducing, I encourage the reader to see the [previous post](https://colab.research.google.com/drive/1XNVNLcUzlpWT0jwS5__p0qXhF7P9tGqd#scrollTo=H5Z4NUdSxgVy), where we explain Hilbert spaces in greater detail.\n",
        "\n",
        "### Representer Theorem\n",
        "\n",
        "Implicit in the last post was a [key insight](https://en.wikipedia.org/wiki/Representer_theorem) that makes kernel methods tractable. The optimization problem posed above operates in an *infinite dimensional function space* $\\mathcal H$, yet for reasons we shall see shortly, the solution lies only in a *finite (p) dimensional sub-space*. \n",
        "\n",
        "The key observation can be made by decomposing the function $f$ into $S = \\text{span}\\{ K(\\cdot, \\mathbf x_i) \\}_{i=1}^p$ and it's orthogonal complement $\\overline{S}$.\n",
        "\n",
        "$$ f(\\mathbf x) = \\sum_{i=1}^p \\alpha_i K(\\mathbf x,\\mathbf x_i) + v(\\mathbf x)$$\n",
        "\n",
        "where $v(\\cdot) \\in \\overline{S}$. By the Reproducing property of the kernel, the empirical loss $\\sum_i \\ell(f(\\mathbf x_i),y_i)$ is independent of $v$ since\n",
        "\n",
        "$$ f(\\mathbf x_i) = \\left< f, K(\\mathbf x_i,\\cdot) \\right>_{\\mathcal H} = \\sum_j \\alpha_j \\left< K(\\mathbf x_j, \\cdot),K(\\mathbf x_i,\\cdot) \\right>_{\\mathcal H} + \\left< v, K(\\mathbf x_i,\\cdot) \\right>_{\\mathcal H} = \\sum_j \\alpha_j K(\\mathbf x_i,\\mathbf x_j)$$\n",
        "\n",
        "The Hilbert norm penalty does, however, depend on $v$ and achieves its minimum only when $v=0$\n",
        "\n",
        "$$ \\left< f, f \\right>_{\\mathcal H} = \\sum_{ij} \\alpha_i \\alpha_j K(\\mathbf x_i,\\mathbf x_j) + \\left< v,v \\right>_{\\mathcal H} \\geq \\sum_{ij} \\alpha_i \\alpha_j K(\\mathbf x_i,\\mathbf x_j) $$\n",
        "\n",
        "where the inequality is tight for $v = 0$. Therefore, the solution to the optimization problem posed above lies in $f \\in S$. \n",
        "\n",
        "### Least Squares\n",
        "\n",
        "If we specialize to least squares error for empirical cost, we can compute $\\alpha$ in closed form\n",
        "\n",
        "$$ \\min_{f \\in \\mathcal H} \\sum_{i=1}^p (f(\\mathbf x_i) - y_i)^2 + \\lambda \\left< f,f\\right>_{\\mathcal H} = \\min_{\\alpha \\in \\mathbb{R}^p} \\alpha^\\top \\mathbf K^2 \\mathbf \\alpha - 2 \\alpha^\\top \\mathbf K \\mathbf y + |\\mathbf y|^2 + \\lambda \\mathbf \\alpha^\\top \\mathbf K \\mathbf \\alpha$$\n",
        "\n",
        "Optimizing with respect this quadratic function with respect to $\\mathbf \\alpha $, we find that the optimum satisfies\n",
        "\n",
        "$$ (\\mathbf K + \\lambda \\mathbf I) \\alpha = \\mathbf y$$\n",
        "\n",
        "This is just a system of $p$ equations with $p$ unknowns. Further $\\mathbf K + \\lambda \\mathbf I$ is invertible since the kernel is positive semidefinite. Ridgeless regression $\\lambda \\to 0$ is possible when $\\mathbf K$ is positive definite. \n",
        "\n",
        "\n",
        "## Numerical Challenge of Solving Large Linear Systems\n",
        "\n",
        "We have discovered that to perform kernel regression with a least squares cost is the same as solving a linear system of $p$ variables with $p$ equations. \n",
        "\n",
        "The naive method to solve a linear system is matrix inversion. What is the numerical cost to invert a $p\\times p$ matrix? \n",
        "\n",
        "### Numerical Scaling of Matrix Inversion\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDYU6R68-SXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c55c1073-581c-4194-bc7b-48673ee793be"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "pvals = [100,200,500,1000,2000,5000,7500,8000]\n",
        "times = []\n",
        "for i,p in enumerate(pvals):\n",
        "  K = np.random.standard_normal((p,p))\n",
        "  start = time.perf_counter()\n",
        "  Kinv = np.linalg.inv(K)\n",
        "  end = time.perf_counter()\n",
        "  times += [end -start]\n",
        "\n",
        "pcube = np.array(pvals)**3\n",
        "plt.loglog(pvals, times, label = 'experiment')\n",
        "plt.loglog(pvals, pcube / pcube[-1] * times[-1], '--', label = r'$p^3$')\n",
        "plt.legend()\n",
        "plt.xlabel('p', fontsize = 20)\n",
        "plt.ylabel('time', fontsize = 20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIMU1lNyDD_v",
        "colab_type": "text"
      },
      "source": [
        "# Straightforward Inversion Does Not Scale\n",
        "\n",
        "### Computation\n",
        "The lines for $p^3$ and the time required to invert the matrix are roughly parallel on a log-log plot, indicating that solving a $p \\times p$ linear system requires $\\mathcal O(p^3)$ operations. Modern machine learning datasets can have $10^6$ data points (ImageNet has roughly 1.6 M data points). Kernel methods would therefore naively require $\\sim 10^{18}$ operations to solve the linear system derived above! This would be challenging even for modern [supercomputers](https://en.wikipedia.org/wiki/Supercomputer#Performance_measurement).\n",
        "\n",
        "### Memory\n",
        "\n",
        "Straightforward inversion techniques typically require storing in memory the entire $p \\times p$ matrix. The memory requirements therefore scale like $\\mathcal O(p^2)$. This quickly becomes prohibitive. To solve even MNIST or CIFAR would require several gigabytes of RAM. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6mJls3ZLY_M",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent / Richardson Iteration\n",
        "\n",
        "Can we develop an iterative algorithm to reduce the number of computations required to solve $\\mathbf K \\alpha = \\mathbf y$?\n",
        "\n",
        "Let's introduce the following objective function\n",
        "\n",
        "$$ \\mathcal L =  ||\\mathbf K^{1/2} \\alpha - \\mathbf K^{-1/2} \\mathbf y||^2$$\n",
        "\n",
        "which has a global minimum $\\mathcal L = 0$ at $\\alpha^* = \\mathbf K^{-1} \\mathbf y$. Note that this cost function is not the training error $||\\mathbf K \\alpha - \\mathbf y||^2$, but both losses have the same global minimizer. \n",
        "\n",
        "The gradient descent dynamics for this cost \n",
        "\n",
        "$$ \\alpha_{t+1} - \\alpha^* = \\alpha_t - \\eta \\frac{\\partial \\mathcal L}{\\partial \\alpha} = \\alpha_t - \\eta (\\mathbf K \\alpha_t - \\mathbf y) = \\alpha_t - \\eta \\mathbf K \\alpha_t  + \\eta \\mathbf K \\alpha^* = (\\mathbf I - \\eta \\mathbf K) (\\alpha_t - \\alpha^*)$$\n",
        "\n",
        "The solution to the recursion above is  \n",
        "\n",
        "$$\\alpha_t - \\alpha^* = - (\\mathbf I - \\eta \\mathbf K)^t \\alpha^*$$\n",
        "\n",
        "Great! So there is an iterative procedure that we could use to find $\\alpha$ rather than inverting the gram matrix. Each step of gradient descent costs $\\mathcal O(p^2)$ operations. For this method to outperform the naive matrix inversion, this algorithm needs to converge in fewer than $\\sim p$ iterations. Does this happen in realistic situations?\n",
        "\n",
        "## Dynamics under Eigendecomposition\n",
        "\n",
        "It is much easier to analyze trajectories of Richardson iteration in the eigenbasis of the kernel $\\mathbf K$. We saw in the last blog post that this decomposition plays a key role in understanding generalization as well. \n",
        "\n",
        "$$ K = \\sum_{k=1}^p \\lambda_k \\mathbf u_k \\mathbf u_k^\\top \\ , \\ \\alpha_t - \\alpha* = \\sum_{k=1}^p e_k(t) \\mathbf u_k $$\n",
        "\n",
        "The dynamics decouple in this basis and give\n",
        "$$ e_k(t) = (1-\\eta \\lambda_k)^t e_k(0) $$\n",
        "\n",
        "Therefore, exponential convergence of each $e_k(t) \\to 0$ is attained provided we choose a small enough learning rate\n",
        " $$\\forall k \\ , \\ |1-\\eta \\lambda_k| < 1 \\implies \\eta < \\frac{2}{\\lambda_{max}} $$\n",
        "\n",
        "\n",
        "### Problem: Large Range of Eigenvalues\n",
        "\n",
        "Typical kernel matrices can have very large range of eigenvalues that scale over multiple decades. The rate of convergence for the smallest eigenvalue is\n",
        "$$ e_p = (1-\\eta \\lambda_p)^t e_p(0)$$\n"
      ]
    }
  ]
}